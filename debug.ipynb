{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, accuracy_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from input_sampling import InputSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = ['Sex', 'Embarked']\n",
    "# num = ['Pclass', 'Age', 'Parch', 'Fare', 'SibSp']\n",
    "# train_set = pd.read_csv('train.csv')\n",
    "# train_set = train_set.fillna({\n",
    "#     'Pclass': train_set['Pclass'].mean(),\n",
    "#     'Age': train_set['Age'].mean(),\n",
    "#     'Parch': train_set['Parch'].mean(),\n",
    "#     'Fare': train_set['Fare'].mean(),\n",
    "#     'SibSp': train_set['SibSp'].mean()\n",
    "# })\n",
    "\n",
    "# y = train_set['Survived']\n",
    "# X = train_set[cat + num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = InputSampler(num, cat, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler.sampleRFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Best performer:\\n[[0.8324022346368715,\\n  RandomizedSearchCV(cv=5,\\n                     estimator=Pipeline(steps=[('preprocessor',\\n                                                ColumnTransformer(transformers=[('scaler',\\n                                                                                 StandardScaler(),\\n                                                                                 ['Pclass',\\n                                                                                  'Age',\\n                                                                                  'Parch',\\n                                                                                  'Fare']),\\n                                                                                ('onehot',\\n                                                                                 OneHotEncoder(),\\n                                                                                 ['Sex',\\n                                                                                  'Embarked'])])),\\n                                               ('classifier',\\n                                                RandomForestClassifier(random_state=42))]),\\n                     n_iter=100, n_jobs=-1,\\n                     param_distributions={'classifier__bootstrap': [True, False],\\n                                          'classi...\\n                                          'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3FF2AA10>,\\n                                          'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3FF2A510>,\\n                                          'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3F883810>},\\n                     random_state=42, verbose=2),\\n  [['Pclass', 'Age', 'Parch', 'Fare'], ['Sex', 'Embarked']]]\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Best performer:\n",
    "[[0.8324022346368715,\n",
    "  RandomizedSearchCV(cv=5,\n",
    "                     estimator=Pipeline(steps=[('preprocessor',\n",
    "                                                ColumnTransformer(transformers=[('scaler',\n",
    "                                                                                 StandardScaler(),\n",
    "                                                                                 ['Pclass',\n",
    "                                                                                  'Age',\n",
    "                                                                                  'Parch',\n",
    "                                                                                  'Fare']),\n",
    "                                                                                ('onehot',\n",
    "                                                                                 OneHotEncoder(),\n",
    "                                                                                 ['Sex',\n",
    "                                                                                  'Embarked'])])),\n",
    "                                               ('classifier',\n",
    "                                                RandomForestClassifier(random_state=42))]),\n",
    "                     n_iter=100, n_jobs=-1,\n",
    "                     param_distributions={'classifier__bootstrap': [True, False],\n",
    "                                          'classi...\n",
    "                                          'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3FF2AA10>,\n",
    "                                          'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3FF2A510>,\n",
    "                                          'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3F883810>},\n",
    "                     random_state=42, verbose=2),\n",
    "  [['Pclass', 'Age', 'Parch', 'Fare'], ['Sex', 'Embarked']]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Sex', 'Embarked']\n",
    "num = ['Pclass', 'Age', 'Parch', 'Fare']\n",
    "train_set = pd.read_csv('train.csv')\n",
    "train_set = train_set.fillna({\n",
    "    'Pclass': train_set['Pclass'].mean(),\n",
    "    'Age': train_set['Age'].mean(),\n",
    "    'Parch': train_set['Parch'].mean(),\n",
    "    'Fare': train_set['Fare'].mean(),\n",
    "})\n",
    "\n",
    "y = train_set['Survived']\n",
    "X = train_set[cat + num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = InputSampler(num, cat, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 250 candidates, totalling 1250 fits\n",
      "[0.8156424581005587, RandomizedSearchCV(cv=5,\n",
      "                   estimator=Pipeline(steps=[('preprocessor',\n",
      "                                              ColumnTransformer(transformers=[('scaler',\n",
      "                                                                               StandardScaler(),\n",
      "                                                                               ['Pclass',\n",
      "                                                                                'Age',\n",
      "                                                                                'Parch',\n",
      "                                                                                'Fare']),\n",
      "                                                                              ('onehot',\n",
      "                                                                               OneHotEncoder(),\n",
      "                                                                               ['Sex',\n",
      "                                                                                'Embarked'])])),\n",
      "                                             ('classifier',\n",
      "                                              RandomForestClassifier(random_state=42))]),\n",
      "                   n_iter=250, n_jobs=-1,\n",
      "                   param_distributions={'classifier__bootstrap': [True, False],\n",
      "                                        'classifier__criterion': ['gini',\n",
      "                                                                  'entropy'],\n",
      "                                        'classifier__max_depth': [10, 20, 30,\n",
      "                                                                  40, 50, 60,\n",
      "                                                                  70, 80, 90,\n",
      "                                                                  100, None],\n",
      "                                        'classifier__max_features': [None,\n",
      "                                                                     'sqrt',\n",
      "                                                                     'log2'],\n",
      "                                        'classifier__min_samples_leaf': [1, 2,\n",
      "                                                                         4],\n",
      "                                        'classifier__min_samples_split': [2, 5,\n",
      "                                                                          10],\n",
      "                                        'classifier__n_estimators': [100, 200,\n",
      "                                                                     300, 400,\n",
      "                                                                     500, 600,\n",
      "                                                                     700, 800,\n",
      "                                                                     900, 1000,\n",
      "                                                                     1100]},\n",
      "                   random_state=42, verbose=2), [['Pclass', 'Age', 'Parch', 'Fare'], ['Sex', 'Embarked']], [{'classifier__n_estimators': 600, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': 10, 'classifier__criterion': 'gini', 'classifier__bootstrap': False}, 0.8258839751797499, Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('scaler', StandardScaler(),\n",
      "                                                  ['Pclass', 'Age', 'Parch',\n",
      "                                                   'Fare']),\n",
      "                                                 ('onehot', OneHotEncoder(),\n",
      "                                                  ['Sex', 'Embarked'])])),\n",
      "                ('classifier',\n",
      "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
      "                                        max_features='log2',\n",
      "                                        min_samples_split=10, n_estimators=600,\n",
      "                                        random_state=42))])]]\n",
      "Highest = 0\n",
      "Iteration = 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m RFC_optimized \u001b[38;5;241m=\u001b[39m sampler\u001b[38;5;241m.\u001b[39msampleRFC()\n",
      "File \u001b[1;32me:\\GitHub\\Kaggle-Titanic\\input_sampling.py:80\u001b[0m, in \u001b[0;36mInputSampler.sampleRFC\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32me:\\GitHub\\Kaggle-Titanic\\input_sampling.py:80\u001b[0m, in \u001b[0;36mInputSampler.sampleRFC.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x:x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "RFC_optimized = sampler.sampleRFC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(sampler.var_combinations[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = sampler.sampleLogR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_performers = models[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = pd.read_csv('test.csv')\n",
    "# test_set = test_set.fillna({\n",
    "#     'Pclass': test_set['Pclass'].mean(),\n",
    "#     'Age': test_set['Age'].mean(),\n",
    "#     'Parch': test_set['Parch'].mean(),\n",
    "#     'Fare': test_set['Fare'].mean(),\n",
    "#     'SibSp': test_set['SibSp'].mean()\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for logr in top_performers:\n",
    "#     model = logr[1].fit(train_set[logr[2][0]+logr[2][1]], train_set['Survived'])\n",
    "#     predictions.append((model.predict_proba(test_set[logr[2][0]+logr[2][1]])[:, 1] >= logr[3]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_dfs = []\n",
    "# for y in predictions:\n",
    "#     df = pd.DataFrame({'PassengerId': test_set['PassengerId'], 'Survived': list(y)})\n",
    "#     prediction_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_dfs[0].to_csv('submission_df0_logr.csv', index=False) # .75119\n",
    "# prediction_dfs[1].to_csv('submission_df1_logr.csv', index=False) # .74880\n",
    "# prediction_dfs[2].to_csv('submission_df2_logr.csv', index=False) # .74641\n",
    "# prediction_dfs[3].to_csv('submission_df3_logr.csv', index=False) # .74641\n",
    "# prediction_dfs[4].to_csv('submission_df4_logr.csv', index=False) # .74401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate_prediction = []\n",
    "# for idx in range(len(predictions[0])):\n",
    "#     ct = {0:0, 1:1}\n",
    "#     for prediction in prediction_dfs:\n",
    "#         if prediction['Survived'].iloc[idx] == 1:\n",
    "#             ct[1] += 1\n",
    "#         else:\n",
    "#             ct[0] += 1\n",
    "#     if ct[0] > ct[1]:\n",
    "#         aggregate_prediction.append(0)\n",
    "#     else:\n",
    "#         aggregate_prediction.append(1)\n",
    "# aggregate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_df = pd.DataFrame({'PassengerId': test_set['PassengerId'], 'Survived': aggregate_prediction})\n",
    "# agg_df.to_csv('submission_agg_0-5_logr.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
