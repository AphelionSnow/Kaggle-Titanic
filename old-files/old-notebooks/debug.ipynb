{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, accuracy_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from input_sampling import InputSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['Sex', 'Embarked']\n",
    "num = ['Pclass', 'Age', 'Parch', 'Fare', 'SibSp']\n",
    "train_set = pd.read_csv('train.csv')\n",
    "train_set = train_set.fillna({\n",
    "    'Pclass': train_set['Pclass'].mean(),\n",
    "    'Age': train_set['Age'].mean(),\n",
    "    'Parch': train_set['Parch'].mean(),\n",
    "    'Fare': train_set['Fare'].mean(),\n",
    "    'SibSp': train_set['SibSp'].mean()\n",
    "})\n",
    "\n",
    "y = train_set['Survived']\n",
    "X = train_set[cat + num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Age&#x27;, &#x27;Parch&#x27;,\n",
       "                                                   &#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;onehot&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;Embarked&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
       "                                        max_features=&#x27;log2&#x27;,\n",
       "                                        min_samples_split=10, n_estimators=600,\n",
       "                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;Pclass&#x27;, &#x27;Age&#x27;, &#x27;Parch&#x27;,\n",
       "                                                   &#x27;Fare&#x27;]),\n",
       "                                                 (&#x27;onehot&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;Embarked&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
       "                                        max_features=&#x27;log2&#x27;,\n",
       "                                        min_samples_split=10, n_estimators=600,\n",
       "                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;scaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;Pclass&#x27;, &#x27;Age&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;]),\n",
       "                                (&#x27;onehot&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;Sex&#x27;, &#x27;Embarked&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">scaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Pclass&#x27;, &#x27;Age&#x27;, &#x27;Parch&#x27;, &#x27;Fare&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;, &#x27;Embarked&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=10, max_features=&#x27;log2&#x27;,\n",
       "                       min_samples_split=10, n_estimators=600, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('scaler', StandardScaler(),\n",
       "                                                  ['Pclass', 'Age', 'Parch',\n",
       "                                                   'Fare']),\n",
       "                                                 ('onehot', OneHotEncoder(),\n",
       "                                                  ['Sex', 'Embarked'])])),\n",
       "                ('classifier',\n",
       "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
       "                                        max_features='log2',\n",
       "                                        min_samples_split=10, n_estimators=600,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers = []\n",
    "transformers.append(('scaler', StandardScaler(), num))\n",
    "transformers.append(('onehot', OneHotEncoder(), cat))\n",
    "preprocessor = ColumnTransformer(transformers=transformers)\n",
    "pipeline = Pipeline(steps=[\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', RandomForestClassifier())\n",
    "            ])\n",
    "pipeline.set_params(classifier__bootstrap=False, classifier__max_depth=10, classifier__max_features='log2', classifier__min_samples_split=10, classifier__n_estimators=600, classifier__random_state=42)\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('test.csv')\n",
    "test_set = test_set.fillna({\n",
    "    'Pclass': test_set['Pclass'].mean(),\n",
    "    'Age': test_set['Age'].mean(),\n",
    "    'Parch': test_set['Parch'].mean(),\n",
    "    'Fare': test_set['Fare'].mean(),\n",
    "    'SibSp': test_set['SibSp'].mean()\n",
    "})\n",
    "X_test = test_set[cat + num]\n",
    "pred = pipeline.predict(X_test)\n",
    "pred_df = pd.DataFrame({'PassengerId': test_set['PassengerId'], 'Survived': pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(os.path.join('submissions', 'rf_optimized_1.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[0.7039106145251397, RandomizedSearchCV(cv=5,\n",
      "                   estimator=Pipeline(steps=[('preprocessor',\n",
      "                                              ColumnTransformer(transformers=[('scaler',\n",
      "                                                                               StandardScaler(),\n",
      "                                                                               ['Pclass'])])),\n",
      "                                             ('classifier',\n",
      "                                              RandomForestClassifier(random_state=42))]),\n",
      "                   n_iter=100, n_jobs=-1,\n",
      "                   param_distributions={'classifier__bootstrap': [True, False],\n",
      "                                        'classifier__criterion': ['gini',\n",
      "                                                                  'entropy'],\n",
      "                                        'classifier__max_depth': <scipy....\n",
      "                                        'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000261018C3BD0>,\n",
      "                                        'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000261018C3710>,\n",
      "                                        'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000261018C2750>},\n",
      "                   random_state=42, verbose=2), [['Pclass'], []]]\n",
      "Highest = 0\n",
      "Iteration = 1\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[0.5921787709497207, RandomizedSearchCV(cv=5,\n",
      "                   estimator=Pipeline(steps=[('preprocessor',\n",
      "                                              ColumnTransformer(transformers=[('scaler',\n",
      "                                                                               StandardScaler(),\n",
      "                                                                               ['Age'])])),\n",
      "                                             ('classifier',\n",
      "                                              RandomForestClassifier(random_state=42))]),\n",
      "                   n_iter=100, n_jobs=-1,\n",
      "                   param_distributions={'classifier__bootstrap': [True, False],\n",
      "                                        'classifier__criterion': ['gini',\n",
      "                                                                  'entropy'],\n",
      "                                        'classifier__max_depth': <scipy.sta...\n",
      "                                        'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000261018C3BD0>,\n",
      "                                        'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000261018C3710>,\n",
      "                                        'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x00000261018C2750>},\n",
      "                   random_state=42, verbose=2), [['Age'], []]]\n",
      "Highest = 0.7039106145251397\n",
      "Iteration = 2\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Best performer:\n",
    "\"Best performer:\\n[[0.8324022346368715,\\n  RandomizedSearchCV(cv=5,\\n                     estimator=Pipeline(steps=[('preprocessor',\\n                                                ColumnTransformer(transformers=[('scaler',\\n                                                                                 StandardScaler(),\\n                                                                                 ['Pclass',\\n                                                                                  'Age',\\n                                                                                  'Parch',\\n                                                                                  'Fare']),\\n                                                                                ('onehot',\\n                                                                                 OneHotEncoder(),\\n                                                                                 ['Sex',\\n                                                                                  'Embarked'])])),\\n                                               ('classifier',\\n                                                RandomForestClassifier(random_state=42))]),\\n                     n_iter=100, n_jobs=-1,\\n                     param_distributions={'classifier__bootstrap': [True, False],\\n                                          'classi...\\n                                          'classifier__min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3FF2AA10>,\\n                                          'classifier__min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3FF2A510>,\\n                                          'classifier__n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000015A3F883810>},\\n                     random_state=42, verbose=2),\\n  [['Pclass', 'Age', 'Parch', 'Fare'], ['Sex', 'Embarked']]]\\n\"\n",
    "Fitting 5 folds for each of 250 candidates, totalling 1250 fits\n",
    "[0.8156424581005587, RandomizedSearchCV(cv=5,\n",
    "                   estimator=Pipeline(steps=[('preprocessor',\n",
    "                                              ColumnTransformer(transformers=[('scaler',\n",
    "                                                                               StandardScaler(),\n",
    "                                                                               ['Pclass',\n",
    "                                                                                'Age',\n",
    "                                                                                'Parch',\n",
    "                                                                                'Fare']),\n",
    "                                                                              ('onehot',\n",
    "                                                                               OneHotEncoder(),\n",
    "                                                                               ['Sex',\n",
    "                                                                                'Embarked'])])),\n",
    "                                             ('classifier',\n",
    "                                              RandomForestClassifier(random_state=42))]),\n",
    "                   n_iter=250, n_jobs=-1,\n",
    "                   param_distributions={'classifier__bootstrap': [True, False],\n",
    "                                        'classifier__criterion': ['gini',\n",
    "                                                                  'entropy'],\n",
    "                                        'classifier__max_depth': [10, 20, 30,\n",
    "                                                                  40, 50, 60,\n",
    "                                                                  70, 80, 90,\n",
    "                                                                  100, None],\n",
    "                                        'classifier__max_features': [None,\n",
    "                                                                     'sqrt',\n",
    "                                                                     'log2'],\n",
    "                                        'classifier__min_samples_leaf': [1, 2,\n",
    "                                                                         4],\n",
    "                                        'classifier__min_samples_split': [2, 5,\n",
    "                                                                          10],\n",
    "                                        'classifier__n_estimators': [100, 200,\n",
    "                                                                     300, 400,\n",
    "                                                                     500, 600,\n",
    "                                                                     700, 800,\n",
    "                                                                     900, 1000,\n",
    "                                                                     1100]},\n",
    "                   random_state=42, verbose=2), [['Pclass', 'Age', 'Parch', 'Fare'], ['Sex', 'Embarked']], [{'classifier__n_estimators': 600, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': 10, 'classifier__criterion': 'gini', 'classifier__bootstrap': False}, 0.8258839751797499, Pipeline(steps=[('preprocessor',\n",
    "                 ColumnTransformer(transformers=[('scaler', StandardScaler(),\n",
    "                                                  ['Pclass', 'Age', 'Parch',\n",
    "                                                   'Fare']),\n",
    "                                                 ('onehot', OneHotEncoder(),\n",
    "                                                  ['Sex', 'Embarked'])])),\n",
    "                ('classifier',\n",
    "                 RandomForestClassifier(bootstrap=False, max_depth=10,\n",
    "                                        max_features='log2',\n",
    "                                        min_samples_split=10, n_estimators=600,\n",
    "                                        random_state=42))])]]\n",
    "Highest = 0\n",
    "Iteration = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(sampler.var_combinations[3][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = sampler.sampleLogR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_performers = models[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = pd.read_csv('test.csv')\n",
    "# test_set = test_set.fillna({\n",
    "#     'Pclass': test_set['Pclass'].mean(),\n",
    "#     'Age': test_set['Age'].mean(),\n",
    "#     'Parch': test_set['Parch'].mean(),\n",
    "#     'Fare': test_set['Fare'].mean(),\n",
    "#     'SibSp': test_set['SibSp'].mean()\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = []\n",
    "# for logr in top_performers:\n",
    "#     model = logr[1].fit(train_set[logr[2][0]+logr[2][1]], train_set['Survived'])\n",
    "#     predictions.append((model.predict_proba(test_set[logr[2][0]+logr[2][1]])[:, 1] >= logr[3]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_dfs = []\n",
    "# for y in predictions:\n",
    "#     df = pd.DataFrame({'PassengerId': test_set['PassengerId'], 'Survived': list(y)})\n",
    "#     prediction_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_dfs[0].to_csv('submission_df0_logr.csv', index=False) # .75119\n",
    "# prediction_dfs[1].to_csv('submission_df1_logr.csv', index=False) # .74880\n",
    "# prediction_dfs[2].to_csv('submission_df2_logr.csv', index=False) # .74641\n",
    "# prediction_dfs[3].to_csv('submission_df3_logr.csv', index=False) # .74641\n",
    "# prediction_dfs[4].to_csv('submission_df4_logr.csv', index=False) # .74401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate_prediction = []\n",
    "# for idx in range(len(predictions[0])):\n",
    "#     ct = {0:0, 1:1}\n",
    "#     for prediction in prediction_dfs:\n",
    "#         if prediction['Survived'].iloc[idx] == 1:\n",
    "#             ct[1] += 1\n",
    "#         else:\n",
    "#             ct[0] += 1\n",
    "#     if ct[0] > ct[1]:\n",
    "#         aggregate_prediction.append(0)\n",
    "#     else:\n",
    "#         aggregate_prediction.append(1)\n",
    "# aggregate_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_df = pd.DataFrame({'PassengerId': test_set['PassengerId'], 'Survived': aggregate_prediction})\n",
    "# agg_df.to_csv('submission_agg_0-5_logr.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
